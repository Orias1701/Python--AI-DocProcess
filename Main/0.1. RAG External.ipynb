{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import faiss\n",
    "import logging\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from Libraries import A0_MyUtils as A0, A1_TextProcess as A1, A2_PdfProcess as A2\n",
    "from Libraries import B1_ExtractData as B1, B2_MergeData as B2, B3_GetStructures as B3\n",
    "from Libraries import B4_ChunkMaster as B4, B5_ChunkFlex as B5, B6_ChunkFixed as B6\n",
    "from Libraries import C1_CreateSchema as C1, C2_Embedding as C2, C3_CheckStruct as C3\n",
    "from Libraries import D0_FaissConvert as D0, D1_Search as D1, D2_Rerank as D2, D3_Respond as D3\n",
    "from Config import Widgets, Configs, ModelLoader as ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23fd2f52df47494abc50c196c3f3e631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='File:  ', index=2, layout=Layout(width='50%'), options=('Harvard_Regulati…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91dd665231d4a5792c7bff42bb53886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='contents', description='Data Key: ', layout=Layout(width='50%'), placeholder='Defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8568ea2d5e44984b898ff1902900038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Type:  ', index=1, layout=Layout(width='50%'), options=('QA', 'Data'), va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6ac9e13a574dbbb39b1728153e8dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Model: ', index=1, layout=Layout(width='90%'), options=('Auto Model', 'Sentence Transfor…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867a65cb6ab5404a8f5fd1aa4ac7c762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Embedder: ', index=2, layout=Layout(width='90%'), options=('vinai/phobert-base', 'keepit…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66083ec07ce344a9a3a333b8dd47ffdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Searcher: ', index=1, layout=Layout(width='90%'), options=('faiss.IndexHNSWFlat', 'faiss…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78e9ed1efb5437b9584ce5cd18ae75c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Reranker: ', layout=Layout(width='90%'), options=('BAAI/bge-reranker-base',), value='BAA…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bcc795beb4749b9918db3d08368c0de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Response: ', layout=Layout(width='90%'), options=('gemini-2.0-flash-exp', 'vinai/PhoGPT-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9206e5bbb3534bd2af8d58a5ac27d5ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='API Key:', index=4, layout=Layout(width='90%'), options=('AIzaSyDaHS-8h6GJkyVPhoX4svvYeB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "159a07f7e270483fad4c09d09a62803c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='success', description='Save State', style=ButtonStyle()), Button(button_st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets_list = Widgets.create_name_form()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model   : Sentence Transformer\n",
      "Type    : Data\n",
      "Embedder: VoVanPhuc/sup-SimCSE-VietNamese-phobert-base\n",
      "Searcher: faiss.IndexFlatIP\n",
      "Reranker: BAAI/bge-reranker-base\n",
      "Responer: gemini-2.0-flash-exp\n",
      "Data Key: contents\n",
      "Embe Key: embeddings\n",
      "File    : HNMU_Regulations\n",
      "Dcment  : ../Docs/HNMU_Regulations.pdf\n",
      "Extract : ../Data/HNMU_Regulations/Data_HNMU_Regulations_Texts_Extracted.json\n",
      "Merge   : ../Data/HNMU_Regulations/Data_HNMU_Regulations_Texts_Merged.json\n",
      "Struct  : ../Data/HNMU_Regulations/Data_HNMU_Regulations_Texts_Struct.json\n",
      "Chunked : ../Data/HNMU_Regulations/Data_HNMU_Regulations_Texts_Chunks.json\n",
      "Segment : ../Data/HNMU_Regulations/Data_HNMU_Regulations_Texts_Segment.json\n",
      "Torch   : ../Data/HNMU_Regulations/Data_HNMU_Regulations_Embeddings.pt\n",
      "Faiss   : ../Data/HNMU_Regulations/Data_HNMU_Regulations_Embeddings.faiss\n",
      "Mapping : ../Data/HNMU_Regulations/Data_HNMU_Regulations_Embeddings_mapping.json\n",
      "Map Data: ../Data/HNMU_Regulations/Data_HNMU_Regulations_Embeddings_map_data.json\n",
      "Meta    : ../Data/HNMU_Regulations/Data_HNMU_Regulations_Embeddings_meta.json\n",
      "Schema  : ../Data/HNMU_Regulations/Data_HNMU_Regulations_Texts_Schema.json\n",
      "API Key : AIzaSyBPjyMfHkS9OW3h7G0kmLSQkWQMfqfX5v0\n",
      "Word    : 200\n"
     ]
    }
   ],
   "source": [
    "config = Configs.WidgetValues(widgets_list)\n",
    "\n",
    "data_foler = config[\"data_folder\"]\n",
    "dcmt_path = config[\"dcmt_path\"]\n",
    "base_folder = config[\"base_folder\"]\n",
    "base_path = config[\"base_path\"]\n",
    "extracted_path = config[\"extracted_path\"]\n",
    "merged_path = config[\"merged_path\"]\n",
    "struct_path = config[\"struct_path\"]\n",
    "chunks_base = config[\"chunks_base\"]\n",
    "chunks_segment = config[\"chunks_segment\"]\n",
    "schema_ex_path = config[\"schema_ex_path\"]\n",
    "embedding_path = config[\"embedding_path\"]\n",
    "torch_path = config[\"torch_path\"]\n",
    "faiss_path = config[\"faiss_path\"]\n",
    "mapping_path = config[\"mapping_path\"]\n",
    "map_data_path = config[\"map_data_path\"]\n",
    "meta_path = config[\"meta_path\"]\n",
    "\n",
    "FILE_TYPE = config[\"FILE_TYPE\"]\n",
    "DATA_KEY = config[\"DATA_KEY\"]\n",
    "EMBE_KEY = config[\"EMBE_KEY\"]\n",
    "SWITCH = config[\"SWITCH\"]\n",
    "EMBEDD_MODEL = config[\"EMBEDD_MODEL\"]\n",
    "SEARCH_EGINE = config[\"SEARCH_EGINE\"]\n",
    "RERANK_MODEL = config[\"RERANK_MODEL\"]\n",
    "RESPON_MODEL = config[\"RESPON_MODEL\"]\n",
    "API_KEY = config[\"API_KEY\"]\n",
    "\n",
    "WORD_LIMIT = config[\"WORD_LIMIT\"]\n",
    "\n",
    "SEARCH_ENGINE = faiss.IndexFlatIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded model\n",
    "cached_path = \"../Models\"\n",
    "\n",
    "# assets\n",
    "assets = \"../Assets/\"\n",
    "exceptions_path = f\"{assets}ex.exceptions.json\"\n",
    "markers_path = f\"{assets}ex.markers.json\"\n",
    "status_path = f\"{assets}ex.status.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA supported: True\n",
      "Number of GPUs: 1\n",
      "Current GPU name: NVIDIA GeForce RTX 2050\n",
      "CUDA device capability: (8, 6)\n",
      "CUDA version (PyTorch): 12.1\n",
      "cuDNN version: 90100\n",
      "ℹ️ Sentece Transformer: VoVanPhuc/sup-SimCSE-VietNamese-phobert-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Orias.ASUS\\miniconda3\\envs\\master\\Lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using: cuda\n"
     ]
    }
   ],
   "source": [
    "ML.CudaCheck()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if SWITCH == \"Auto Model\":\n",
    "    if os.path.exists(cached_path):\n",
    "        tokenizer, model = ML.load_auto_model(cached_path, device)\n",
    "        print(f\"ℹ️ Auto Model: {cached_path}\")\n",
    "        if model is None:\n",
    "            tokenizer, model = ML.load_auto_model(EMBEDD_MODEL, device)\n",
    "    else:\n",
    "        print(f\"ℹ️ Auto Model: {EMBEDD_MODEL}\")\n",
    "        tokenizer, model = ML.load_auto_model(EMBEDD_MODEL, device)\n",
    "\n",
    "elif SWITCH == \"Sentence Transformer\":\n",
    "    if os.path.exists(cached_path):\n",
    "        model = ML.load_sentence_model(cached_path, device)\n",
    "        print(f\"ℹ️ Sentece Transformer: {cached_path}\")\n",
    "\n",
    "        if model is None:\n",
    "            model = ML.load_sentence_model(EMBEDD_MODEL, device)\n",
    "    else:\n",
    "        print(f\"ℹ️ Sentece Transformer: {EMBEDD_MODEL}\")\n",
    "        model = ML.load_sentence_model(EMBEDD_MODEL, device)\n",
    "\n",
    "print(f\"✅ Using: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataExtractor = B1.B1Extractor(\n",
    "    exceptions_path, \n",
    "    markers_path, \n",
    "    status_path, \n",
    "    proper_name_min_count=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "structAnalyzer = B3.StructureAnalyzer(\n",
    "    merged_path = merged_path,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunkBuilder = B4.ChunkBuilder(\n",
    "    struct_path=struct_path,\n",
    "    merged_path=merged_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemaEx = C1.JSONSchemaExtractor(\n",
    "    list_policy=\"first\", \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Embedding = C2.JSONEmbedding(\n",
    "    model=model,\n",
    "    device=\"cuda:0\",\n",
    "    batch_size=32,\n",
    "    show_progress=False,\n",
    "    flatten_mode=\"split\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 15:56:25,222 - INFO - Chỉ giữ 2 field cuối trong schema: {'Article', 'Content'}\n"
     ]
    }
   ],
   "source": [
    "FaissConverter = D0.Torch2FaissConverter(\n",
    "    schema_ex_path=schema_ex_path,\n",
    "    torch_path=torch_path,\n",
    "    faiss_path=faiss_path,\n",
    "    mapping_path=mapping_path,\n",
    "    map_data_path=map_data_path,\n",
    "    keep_last=2,\n",
    "    nlist=100,\n",
    "    mode=EMBE_KEY,\n",
    "    use_pickle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractRun():\n",
    "    extracted_data = dataExtractor.extract(dcmt_path)\n",
    "    A0.write_json(extracted_data, extracted_path, indent=1)\n",
    "\n",
    "    merged_data = B2.mergeLinesToParagraphs(extracted_data)\n",
    "    A0.write_json(merged_data, merged_path, indent=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structRun():\n",
    "    markers = structAnalyzer.extract_markers()\n",
    "\n",
    "    structures = structAnalyzer.build_structures(markers)\n",
    "    print(A0.jsonl_convert(structures))\n",
    "\n",
    "    dedup = structAnalyzer.deduplicate(structures)\n",
    "    print(A0.jsonl_convert(dedup))\n",
    "\n",
    "    top = structAnalyzer.select_top(dedup)\n",
    "    topext = structAnalyzer.extend_top(top, dedup)\n",
    "    print(A0.json_convert(topext, pretty=True))\n",
    "\n",
    "    A0.write_json(topext, struct_path, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkRun():\n",
    "    chunks = chunkBuilder.build()\n",
    "    A0.write_json(chunks, chunks_base, indent=2)\n",
    "\n",
    "    filtered = [item for item in chunks if item.get(\"Level 1\", \"\").strip()]\n",
    "    for i, item in enumerate(filtered, start=1):\n",
    "        item[\"Index\"] = i\n",
    "\n",
    "    A0.write_json(filtered, chunks_segment, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schemaRun():\n",
    "    if os.path.exists(chunks_segment):\n",
    "        schemaEx.schemaRun(chunks_segment, schema_path=schema_ex_path)\n",
    "        chunksSchema = A0.read_json(schema_ex_path)\n",
    "        print(chunksSchema)\n",
    "    else:\n",
    "        print(f\"{chunks_segment} does not exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddingRun():\n",
    "    if os.path.exists(chunks_segment):\n",
    "        Embedding.embeddingRun(\n",
    "            json_path = chunks_segment,\n",
    "            schema_path = schema_ex_path,\n",
    "            torch_path = torch_path,\n",
    "            data_key = DATA_KEY,\n",
    "            embe_key = EMBE_KEY,\n",
    "            skip_if_exists = False,\n",
    "        )\n",
    "        \n",
    "        C3.print_json(DATA_KEY, EMBE_KEY, torch_path)\n",
    "    \n",
    "    else:\n",
    "        print(f\"{chunks_segment} does not exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking fields and their types:\n",
      "New: Index           item 1: Type = number\n",
      "New: Level 1         item 1: Type = string\n",
      "New: Level 2         item 1: Type = string\n",
      "New: Article         item 1: Type = string\n",
      "New: Content         item 1: Type = array\n",
      "Generated schema:\n",
      "{\n",
      "  \"Index\": \"number\",\n",
      "  \"Level 1\": \"string\",\n",
      "  \"Level 2\": \"string\",\n",
      "  \"Article\": \"string\",\n",
      "  \"Content\": \"array\"\n",
      "}\n",
      "{'Index': 'number', 'Level 1': 'string', 'Level 2': 'string', 'Article': 'string', 'Content': 'array'}\n",
      "Đã lưu embedding vào: ../Data/HNMU_Regulations/Data_HNMU_Regulations_Embeddings.pt\n",
      "[contents] Tổng số mục: 468 — In mục index=0\n",
      "{\n",
      "  \"Index\": 1,\n",
      "  \"Level 1\": \"Chương I NHỮNG QUY ĐỊNH CHUNG\",\n",
      "  \"Level 2\": \"Điều 1. Phạm vi điều chỉnh và đối tượng áp dụng\",\n",
      "  \"Article\": \"1. Quy chế này quy định chung về tổ chức và quản lý đào tạo trình độ đại học tại trường Đại học Thủ đô Hà Nội bao gồm: Chương trình đào tạo và thời gian học tập; hình thức và phương thức tổ chức đào t…\",\n",
      "  \"Content\": {\n",
      "    \"__vector_len__\": 0,\n",
      "    \"head\": []\n",
      "  },\n",
      "  \"Level 1 Embedding\": {\n",
      "    \"__vector_len__\": 768,\n",
      "    \"head\": [\n",
      "      -0.2727910876274109,\n",
      "      -0.008815516717731953,\n",
      "      -0.12173040211200714,\n",
      "      -0.7325150370597839,\n",
      "      -0.3437274396419525\n",
      "    ]\n",
      "  },\n",
      "  \"Level 2 Embedding\": {\n",
      "    \"__vector_len__\": 768,\n",
      "    \"head\": [\n",
      "      -0.41686302423477173,\n",
      "      0.4035288095474243,\n",
      "      -0.03286565840244293,\n",
      "      -0.7461373209953308,\n",
      "      -0.5981038808822632\n",
      "    ]\n",
      "  },\n",
      "  \"Article Embedding\": {\n",
      "    \"__vector_len__\": 768,\n",
      "    \"head\": [\n",
      "      0.2182658612728119,\n",
      "      0.032990992069244385,\n",
      "      -0.4094744324684143,\n",
      "      -0.4240751266479492,\n",
      "      -0.2343890368938446\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n",
      "[embeddings] Tổng số mục: 468 — In mục index=0\n",
      "Thống kê nhanh embedding:\n",
      "{\n",
      "  \"num_vectors\": 3,\n",
      "  \"dim_histogram\": {\n",
      "    \"768\": 3\n",
      "  }\n",
      "}\n",
      "\n",
      "Mẫu embedding (đã tóm tắt):\n",
      "{\n",
      "  \"Level 1 Embedding\": {\n",
      "    \"__vector_len__\": 768,\n",
      "    \"head\": [\n",
      "      -0.2727910876274109,\n",
      "      -0.008815516717731953,\n",
      "      -0.12173040211200714,\n",
      "      -0.7325150370597839,\n",
      "      -0.3437274396419525\n",
      "    ]\n",
      "  },\n",
      "  \"Level 2 Embedding\": {\n",
      "    \"__vector_len__\": 768,\n",
      "    \"head\": [\n",
      "      -0.41686302423477173,\n",
      "      0.4035288095474243,\n",
      "      -0.03286565840244293,\n",
      "      -0.7461373209953308,\n",
      "      -0.5981038808822632\n",
      "    ]\n",
      "  },\n",
      "  \"Article Embedding\": {\n",
      "    \"__vector_len__\": 768,\n",
      "    \"head\": [\n",
      "      0.2182658612728119,\n",
      "      0.032990992069244385,\n",
      "      -0.4094744324684143,\n",
      "      -0.4240751266479492,\n",
      "      -0.2343890368938446\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 15:56:45,981 - INFO - Kiểu dữ liệu: <class 'dict'>\n",
      "2025-09-29 15:56:45,982 - INFO - Số lượng khóa cấp cao nhất: 2\n",
      "2025-09-29 15:56:46,985 - INFO - Khóa: contents, Kiểu giá trị: <class 'list'>, Giá trị mẫu: [{'Index': 1, 'Level 1': 'Chương I NHỮNG QUY ĐỊNH CHUNG', 'Level 2': 'Điều 1. Phạm vi điều chỉnh và ...\n",
      "2025-09-29 15:56:47,996 - INFO - Khóa: embeddings, Kiểu giá trị: <class 'list'>, Giá trị mẫu: [{'Level 1 Embedding': [-0.2727910876274109, -0.008815516717731953, -0.12173040211200714, -0.7325150...\n",
      "2025-09-29 15:56:48,009 - INFO - Đang tải file .pt: ../Data/HNMU_Regulations/Data_HNMU_Regulations_Embeddings.pt\n",
      "2025-09-29 15:56:48,188 - INFO - Đang trích xuất embedding và dữ liệu...\n",
      "2025-09-29 15:56:48,239 - INFO - Tìm thấy 1056 embedding.\n",
      "2025-09-29 15:56:48,240 - INFO - Đang tạo chỉ mục FAISS...\n",
      "2025-09-29 15:56:48,244 - INFO - Đang thêm embedding vào chỉ mục...\n",
      "2025-09-29 15:56:48,247 - INFO - Đang lưu ánh xạ khóa vào ../Data/HNMU_Regulations/Data_HNMU_Regulations_Embeddings_mapping.json\n",
      "2025-09-29 15:56:48,250 - INFO - Đang lưu dữ liệu thường vào ../Data/HNMU_Regulations/Data_HNMU_Regulations_Embeddings_map_data.json\n",
      "2025-09-29 15:56:48,258 - INFO - Chuyển đổi hoàn tất.\n"
     ]
    }
   ],
   "source": [
    "if FILE_TYPE == \"Data\":\n",
    "    extractRun()\n",
    "    structRun()\n",
    "    chunkRun()\n",
    "    \n",
    "schemaRun()\n",
    "embeddingRun()\n",
    "FaissConverter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchRun(user_question):\n",
    "    preliminary_results = D1.search_faiss_index(\n",
    "        query = user_question,\n",
    "        embedd_model = EMBEDD_MODEL,\n",
    "        faiss_path = faiss_path,\n",
    "        mapping_path = mapping_path,\n",
    "        mapping_data = map_data_path,\n",
    "        device = device,\n",
    "        k = 2,\n",
    "        min_score = 5,\n",
    "        batches = False,\n",
    "    )\n",
    "    return preliminary_results\n",
    "\n",
    "def rerankRun(user_question, preliminary_results):\n",
    "    reranked_results = D2.rerank_results(\n",
    "        query = user_question,\n",
    "        results = preliminary_results,\n",
    "        reranker_model = RERANK_MODEL,\n",
    "        device = device,\n",
    "        k = 5,\n",
    "        batches = False,\n",
    "    )\n",
    "    context = '\\n\\n'.join(item['text'] for item in reranked_results)\n",
    "    return reranked_results, context\n",
    "\n",
    "def respondRun(user_question, prompt, context=\"\", doc=False):\n",
    "    response = D3.respond_naturally(\n",
    "        user_question = user_question,\n",
    "        context = context,\n",
    "        prompt = prompt,\n",
    "        responser_model = RESPON_MODEL,\n",
    "        score_threshold = 0.85,\n",
    "        max_results = 3,\n",
    "        doc = doc,\n",
    "        gemini_api_key = API_KEY,\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_type = \"Docs\"\n",
    "\n",
    "queries = [\n",
    "    \"Quy chế này quy định những gì và áp dụng cho đối tượng nào\",\n",
    "    \"Sinh viên có thể được thi lại bao nhiêu lần?\",\n",
    "]\n",
    "\n",
    "def chatRun():\n",
    "\n",
    "    prompt_path = f\"Prompts/{prompt_type}_Prompt.txt\"\n",
    "    with open(prompt_path, \"r\", encoding=\"utf-8\") as f: prompt = f.read()\n",
    "\n",
    "    print(\"<< Enter 'exit', 'quit', 'escape', 'bye' or Press ESC to exit >>\")\n",
    "    print(\"Chatbot: Hello there! I'm here to help you!\\n\\n\")\n",
    "\n",
    "    query = -1\n",
    "    while True:\n",
    "        try:\n",
    "            query += 1\n",
    "            if query >= len(queries):\n",
    "                user_input = \"exit\"\n",
    "            else:\n",
    "                user_input = queries[query]\n",
    "\n",
    "            # user_input = input(\"You: \")\n",
    "\n",
    "            user_question = A0.preprocess_text(user_input)\n",
    "            if user_input.strip().lower() in [\"exit\", \"quit\", \"escape\", \"bye\", \"\"]:\n",
    "                print(\"Chatbot: Goodbye!\")\n",
    "                break\n",
    "\n",
    "            print(f\"Query: {user_question}\")\n",
    "\n",
    "            # Bước 1: Search\n",
    "            preliminary_results = searchRun(user_question)\n",
    "            \n",
    "            # Bước 2: Rerank\n",
    "            if preliminary_results:\n",
    "                print(preliminary_results)\n",
    "                reranked_results, context = rerankRun(user_question, preliminary_results)\n",
    "            else:\n",
    "                print(\"Không tìm thấy thông tin!\")\n",
    "\n",
    "            # Bước 3: Generate Response\n",
    "            if (reranked_results):\n",
    "                print(reranked_results)\n",
    "                print(f\"\\n Context:\\n {context}\")\n",
    "                response = respondRun(user_question, prompt, context=\"\", doc=True)\n",
    "            else:\n",
    "                print(\"Rerank thất bại!\")\n",
    "\n",
    "            # Bước 4: Print Response\n",
    "            if response:\n",
    "                print(f\"\\nYou: {user_question}\")\n",
    "                print(f\"Chatbot: {response}\\n\\n\")\n",
    "            else:\n",
    "                print(\"LLM không phản hồi!\")\n",
    "\n",
    "            print(\"=\" * 200)\n",
    "            print(\"\\n\\n\")\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nChatbot: Goodbye!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chatRun()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
