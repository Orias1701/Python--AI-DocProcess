{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import faiss\n",
    "import logging\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from RAGLibrary import Widgets\n",
    "from RAGLibrary import CheckConstruct, CreateSchema, FaissConvert, Embedding, Search, Rerank, Respond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets_list = Widgets.create_name_form()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "force_download = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" DEFINE \"\"\"\n",
    "\n",
    "data   = widgets_list[0] #HBox 1\n",
    "keys   = widgets_list[1] #HBox 2\n",
    "choose = widgets_list[2] #HBox 3\n",
    "\n",
    "embedd_model = widgets_list[3]\n",
    "search_egine = widgets_list[4]\n",
    "rerank_model = widgets_list[5]\n",
    "respon_model = widgets_list[6]\n",
    "API_drop     = widgets_list[7]\n",
    "button_box   = widgets_list[8]\n",
    "\n",
    "# HBox 1\n",
    "file_name = data.children[0]\n",
    "file_type = data.children[1]\n",
    "\n",
    "# HBox 2\n",
    "data_key = keys.children[0]\n",
    "embe_key = keys.children[1]\n",
    "\n",
    "# HBox 3\n",
    "switch_model = choose.children[0]\n",
    "merge_otp    = choose.children[1]\n",
    "path_end_val = choose.children[1]\n",
    "\n",
    "# Get value\n",
    "data_folder   = file_name.value\n",
    "file_type_val = file_type.value\n",
    "\n",
    "data_key_val  = data_key.value\n",
    "embe_key_val  = embe_key.value\n",
    "\n",
    "API_key_val = API_drop.value\n",
    "switch      = switch_model.value\n",
    "merge       = merge_otp.value\n",
    "path_end    = path_end_val.value\n",
    "\n",
    "embedding_model = embedd_model.value\n",
    "searching_egine = search_egine.value\n",
    "reranking_model = rerank_model.value\n",
    "responing_model = respon_model.value\n",
    "\n",
    "\n",
    "# Define\n",
    "base_path = f\"../Data/{data_folder}/{file_type_val}_{data_folder}\"\n",
    "\n",
    "json_file_path = f\"{base_path}_Database.json\"\n",
    "schema_ex_path = f\"{base_path}_Schema.json\"\n",
    "embedding_path = f\"{base_path}_Embeds_{merge}\"\n",
    "\n",
    "torch_path  = f\"{embedding_path}.pt\"\n",
    "faiss_path  = f\"{embedding_path}.faiss\"\n",
    "mapping_path = f\"{embedding_path}_mapping.json\"\n",
    "mapping_data = f\"{embedding_path}_map_data.json\"\n",
    "\n",
    "FILE_TYPE    = file_type_val\n",
    "DATA_KEY     = data_key_val\n",
    "EMBE_KEY     = embe_key_val\n",
    "SWITCH       = switch\n",
    "EMBEDD_MODEL = embedding_model\n",
    "SEARCH_EGINE = searching_egine\n",
    "RERANK_MODEL = reranking_model\n",
    "RESPON_MODEL = responing_model\n",
    "\n",
    "if FILE_TYPE == \"Data\":\n",
    "    MERGE = merge\n",
    "else: \n",
    "    MERGE = \"no_Merge\"\n",
    "\n",
    "API_KEY = API_key_val\n",
    "\n",
    "SEARCH_ENGINE = faiss.IndexFlatIP\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Embedder: {EMBEDD_MODEL}\")\n",
    "print(f\"Searcher: {SEARCH_EGINE}\")\n",
    "print(f\"Reranker: {RERANK_MODEL}\")\n",
    "print(f\"Responer: {RESPON_MODEL}\")\n",
    "print(f\"Data Key: {DATA_KEY}\")\n",
    "print(f\"Embe Key: {EMBE_KEY}\")\n",
    "print(f\"Database: {json_file_path}\")\n",
    "print(f\"Torch   : {torch_path}\")\n",
    "print(f\"Faiss   : {faiss_path}\")\n",
    "print(f\"Mapping : {mapping_path}\")\n",
    "print(f\"Map Data: {mapping_data}\")\n",
    "print(f\"Schema  : {schema_ex_path}\")\n",
    "print(f\"Model   : {SWITCH}\")\n",
    "print(f\"Merge   : {MERGE}\")\n",
    "print(f\"API Key : {API_KEY}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if (SWITCH == \"Auto Model\"):\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(EMBEDD_MODEL, force_download=force_download)\n",
    "        model = AutoModel.from_pretrained(EMBEDD_MODEL, force_download=force_download)\n",
    "        model = model.to(device)\n",
    "        print(\"Model and tokenizer loaded successfully\")\n",
    "    except Exception as e:\n",
    "        raise\n",
    "elif (SWITCH == \"Sentence Transformer\"):\n",
    "    try:\n",
    "        # model = SentenceTransformer(EMBEDD_MODEL).to(device)\n",
    "        model = SentenceTransformer(\"../../cached_model\")\n",
    "        print(\"SentenceTransformer loaded successfully\")\n",
    "    except Exception as e:\n",
    "        raise\n",
    "\n",
    "print(f\"Using: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(json_file_path):\n",
    "    if not os.path.exists(schema_ex_path):\n",
    "        CreateSchema.create_schema(json_file_path, schema_ex_path)\n",
    "    else:\n",
    "        print(f\"{schema_ex_path} alredy existed\")\n",
    "else:\n",
    "    print(f\"{json_file_path} does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(json_file_path):\n",
    "    if not os.path.exists(torch_path):\n",
    "        Embedding.json_embeddings(MERGE, json_file_path, torch_path, schema_ex_path, model, device, DATA_KEY, EMBE_KEY, batches = False)\n",
    "    else: \n",
    "        print(f\"{torch_path} alredy existed\")\n",
    "else:\n",
    "    print(f\"{json_file_path} does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(torch_path):\n",
    "    CheckConstruct.print_json(DATA_KEY, torch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(torch_path):\n",
    "    if not os.path.exists(faiss_path):\n",
    "        FaissConvert.convert_pt_to_faiss(torch_path, faiss_path, mapping_path, mapping_data, DATA_KEY, nlist = 100, use_pickle = False)\n",
    "    else: \n",
    "        print(f\"{faiss_path} alredy existed\")\n",
    "else:\n",
    "    print(f\"{torch_path} does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" MAIN \"\"\"\n",
    "\n",
    "with open(f\"Prompts/Docs_Prompt.txt\", \"r\", encoding=\"utf-8\") as file1:\n",
    "    docs_prompt = file1.read()\n",
    "\n",
    "with open(f\"Prompts/Docs_Prompt.txt\", \"r\", encoding=\"utf-8\") as file2:\n",
    "    natr_prompt = file2.read()\n",
    "\n",
    "print(\"<< Enter 'exit', 'quit', 'escape', 'bye' or Press ESC to exit >>\")\n",
    "print(\"Chatbot: Hello there! I'm here to help you!\")\n",
    "\n",
    "user_input = \"Quy định về đào tạo đại học tại trường Thủ đô Hà Nội\"\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # user_input = input(\"You: \")\n",
    "        user_question = Embedding.preprocess_text(user_input)\n",
    "        if user_input.strip().lower() in [\"exit\", \"quit\", \"escape\", \"bye\", \"\"]:\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break\n",
    "\n",
    "        print(f\"Query: {user_question}\")\n",
    "\n",
    "        #Bước 1: Search\n",
    "        preliminary_results = Search.search_faiss_index(\n",
    "            query= user_question,\n",
    "            embedd_model=EMBEDD_MODEL,\n",
    "            faiss_path=faiss_path,\n",
    "            mapping_path=mapping_path,\n",
    "            data_path=mapping_data,\n",
    "            device=device,\n",
    "            k=10,\n",
    "            batches = False,\n",
    "        )\n",
    "        print(preliminary_results)\n",
    "\n",
    "        # Bước 2: Rerank\n",
    "        reranked_results = Rerank.rerank_results(\n",
    "            query= user_question,\n",
    "            results=preliminary_results,\n",
    "            reranker_model=RERANK_MODEL,\n",
    "            device=device,\n",
    "            k=5,\n",
    "            batches = False,\n",
    "        )\n",
    "        print(reranked_results)\n",
    "\n",
    "        user_prompt = f\"\"\"Câu hỏi: {user_question}\"\"\"\n",
    "\n",
    "        if (reranked_results):\n",
    "            final_prompt = natr_prompt + \"\\n\" + user_prompt\n",
    "        else:\n",
    "            final_prompt = docs_prompt + \"\\n\" + user_prompt\n",
    "\n",
    "        # Bước 3: Generate Response\n",
    "        response, filtered_results = Respond.respond_naturally(\n",
    "            results=reranked_results,\n",
    "            final_prompt = final_prompt,\n",
    "            responser_model=RESPON_MODEL,\n",
    "            score_threshold=0.85,\n",
    "            max_results=3,\n",
    "            gemini_api_key=API_KEY,\n",
    "        )\n",
    "\n",
    "        print(f\"\\nYou: {user_question}\")\n",
    "        print(f\"Chatbot: {response}\")\n",
    "        user_input = \"exit\"\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nChatbot: Goodbye!\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
