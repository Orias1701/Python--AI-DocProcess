{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import faiss\n",
    "import logging\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from RAGLibrary import Widgets, Define\n",
    "from RAGLibrary import CheckConstruct, CreateSchema, FaissConvert, Embedding, Search, Rerank, Respond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd8effdca304ec7976ebb38f2be5f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='File:  ', index=1, layout=Layout(width='33%'), options=('Harvard_Regulati…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "399514860f18440f9506ed3d1921d839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='contents', description='Data Key: ', layout=Layout(width='50%'), placeholder='Defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb7e2d5d2254b168f308e0ccf7fe959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Model: ', index=1, layout=Layout(width='50%'), options=('Auto Model', 'Se…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be553dc39d54a618a7e895de1dcca9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Embedder: ', index=2, layout=Layout(width='90%'), options=('vinai/phobert-base', 'keepit…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ca26ef24404d74b880c05829bee83c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Searcher: ', index=1, layout=Layout(width='90%'), options=('faiss.IndexHNSWFlat', 'faiss…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660618f5226344169e45a9ae7dd220e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Reranker: ', layout=Layout(width='90%'), options=('BAAI/bge-reranker-base',), value='BAA…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a8a0ca8dbd4d8a9d5e3ed6961bd677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Response: ', layout=Layout(width='90%'), options=('gemini-2.0-flash-exp', 'vinai/PhoGPT-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17495bd436eb4c679faef9d80fda7998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='API Key:', index=4, layout=Layout(width='90%'), options=('AIzaSyDaHS-8h6GJkyVPhoX4svvYeB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b352c0d65b04dafb4ded88360d41cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Max Level: ', index=4, layout=Layout(width='50%'), options=('0', '1', '2'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69e553ad2bd41e78e97acace05b2a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50357112fb54c6cafce916fce66c5d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='success', description='Save State', style=ButtonStyle()), Button(button_st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets_list = Widgets.create_name_form()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n",
    "force_download = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedder: VoVanPhuc/sup-SimCSE-VietNamese-phobert-base\n",
      "Searcher: faiss.IndexFlatIP\n",
      "Reranker: BAAI/bge-reranker-base\n",
      "Responer: gemini-2.0-flash-exp\n",
      "Data Key: contents\n",
      "Embe Key: embeddings\n",
      "Dcment  : ../Doc/HNMU_Regulations.pdf\n",
      "Chunked : ../Data/HNMU_Regulations/QA_HNMU_Regulations_Chunks.json\n",
      "Database: ../Data/HNMU_Regulations/QA_HNMU_Regulations_Database.json\n",
      "Torch   : ../Data/HNMU_Regulations/QA_HNMU_Regulations_Embeds_QA.pt\n",
      "Faiss   : ../Data/HNMU_Regulations/QA_HNMU_Regulations_Embeds_QA.faiss\n",
      "Mapping : ../Data/HNMU_Regulations/QA_HNMU_Regulations_Embeds_QA_mapping.json\n",
      "Map Data: ../Data/HNMU_Regulations/QA_HNMU_Regulations_Embeds_QA_map_data.json\n",
      "Schema  : ../Data/HNMU_Regulations/QA_HNMU_Regulations_Schema.json\n",
      "Model   : Sentence Transformer\n",
      "Merge   : no_Merge\n",
      "API Key : AIzaSyBPjyMfHkS9OW3h7G0kmLSQkWQMfqfX5v0\n",
      "Word    : 200\n",
      "Level   : 4\n",
      "Level Values: ['Chương', 'Điều', 'Khoản', 'Nội dung']\n"
     ]
    }
   ],
   "source": [
    "config = Define.WidgetValues(widgets_list)\n",
    "\n",
    "dcmt_path = config[\"dcmt_path\"]\n",
    "base_folder = config[\"base_folder\"]\n",
    "base_path = config[\"base_path\"]\n",
    "chunks_base = config[\"chunks_base\"]\n",
    "json_file_path = config[\"json_file_path\"]\n",
    "schema_ex_path = config[\"schema_ex_path\"]\n",
    "embedding_path = config[\"embedding_path\"]\n",
    "torch_path = config[\"torch_path\"]\n",
    "faiss_path = config[\"faiss_path\"]\n",
    "mapping_path = config[\"mapping_path\"]\n",
    "mapping_data = config[\"mapping_data\"]\n",
    "\n",
    "FILE_TYPE = config[\"FILE_TYPE\"]\n",
    "DATA_KEY = config[\"DATA_KEY\"]\n",
    "EMBE_KEY = config[\"EMBE_KEY\"]\n",
    "SWITCH = config[\"SWITCH\"]\n",
    "EMBEDD_MODEL = config[\"EMBEDD_MODEL\"]\n",
    "SEARCH_EGINE = config[\"SEARCH_EGINE\"]\n",
    "RERANK_MODEL = config[\"RERANK_MODEL\"]\n",
    "RESPON_MODEL = config[\"RESPON_MODEL\"]\n",
    "MERGE = config[\"MERGE\"]\n",
    "API_KEY = config[\"API_KEY\"]\n",
    "\n",
    "WORD_LIMIT = config[\"WORD_LIMIT\"]\n",
    "LEVEL_INPUT = config[\"LEVEL_INPUT\"]\n",
    "LEVEL_VALUES = config[\"LEVEL_VALUES\"]\n",
    "\n",
    "SEARCH_ENGINE = faiss.IndexFlatIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer loaded successfully\n",
      "Using: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if (SWITCH == \"Auto Model\"):\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(EMBEDD_MODEL, force_download=force_download)\n",
    "        model = AutoModel.from_pretrained(EMBEDD_MODEL, force_download=force_download)\n",
    "        model = model.to(device)\n",
    "        print(\"Model and tokenizer loaded successfully\")\n",
    "    except Exception as e:\n",
    "        raise\n",
    "elif (SWITCH == \"Sentence Transformer\"):\n",
    "    try:\n",
    "        model = SentenceTransformer(EMBEDD_MODEL).to(device)\n",
    "        # model = SentenceTransformer(\"../../cached_model\")\n",
    "        print(\"SentenceTransformer loaded successfully\")\n",
    "    except Exception as e:\n",
    "        raise\n",
    "\n",
    "print(f\"Using: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/HNMU_Regulations/QA_HNMU_Regulations_Schema.json alredy existed\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(json_file_path):\n",
    "    if not os.path.exists(schema_ex_path):\n",
    "        CreateSchema.create_schema(json_file_path, schema_ex_path)\n",
    "    else:\n",
    "        print(f\"{schema_ex_path} alredy existed\")\n",
    "else:\n",
    "    print(f\"{json_file_path} does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/HNMU_Regulations/QA_HNMU_Regulations_Embeds_QA.pt alredy existed\n",
      "Bộ dữ liệu đầu tiên từ 'contents':\n",
      "{\n",
      "  \"Câu hỏi\": \"Quy chế này quy định những gì và áp dụng cho đối tượng nào\",\n",
      "  \"Câu trả lời\": \"Quy chế này quy định chung về tổ chức và quản lý đào tạo trình độ đại học tại trường Đại học Thủ đô Hà Nội, bao gồm: Chương trình đào tạo và thời gian học tập; hình thức và phương thức tổ chức đào tạo; lập kế hoạch và tổ chức giảng dạy; đánh giá kết quả học tập và cấp bằng tốt nghiệp; những quy định khác đối với sinh viên. Quy chế này áp dụng trong đào tạo theo hình thức chính quy và hình thức vừa làm vừa học\",\n",
      "  \"Câu hỏi Embedding\": 768,\n",
      "  \"Câu trả lời Embedding\": 768\n",
      "}\n",
      "\n",
      "Bộ embedding đầu tiên từ 'embeddings':\n",
      "{\n",
      "  \"Câu hỏi Embedding\": 768,\n",
      "  \"Câu trả lời Embedding\": 768\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(json_file_path):\n",
    "    if not os.path.exists(torch_path):\n",
    "        # os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"0\"\n",
    "        Embedding.json_embeddings(MERGE, json_file_path, torch_path, schema_ex_path, model, device, DATA_KEY, EMBE_KEY, batches = False)\n",
    "    else: \n",
    "        print(f\"{torch_path} alredy existed\")\n",
    "        CheckConstruct.print_json(DATA_KEY, EMBE_KEY, torch_path)\n",
    "else:\n",
    "    print(f\"{json_file_path} does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/HNMU_Regulations/QA_HNMU_Regulations_Embeds_QA.faiss alredy existed\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(torch_path):\n",
    "    if not os.path.exists(faiss_path):\n",
    "        FaissConvert.convert_pt_to_faiss(torch_path, faiss_path, mapping_path, mapping_data, DATA_KEY, nlist = 100, use_pickle = False)\n",
    "    else: \n",
    "        print(f\"{faiss_path} alredy existed\")\n",
    "else:\n",
    "    print(f\"{torch_path} does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def convert_to_json(preliminary_results):\n",
    "    class LiteralNewlineEncoder(json.JSONEncoder):\n",
    "        def encode(self, o):\n",
    "            # Dùng mặc định encode trước\n",
    "            json_text = super().encode(o)\n",
    "            # Sau đó thay thế \\\\n (escaped newline) thành \\n thật\n",
    "            return json_text.replace(\"\\\\n\", \"\\n \\t \\t \")\n",
    "    \n",
    "    return json.dumps(\n",
    "        preliminary_results,\n",
    "        ensure_ascii=False,\n",
    "        indent=4,\n",
    "        cls=LiteralNewlineEncoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< Enter 'exit', 'quit', 'escape', 'bye' or Press ESC to exit >>\n",
      "Chatbot: Hello there! I'm here to help you!\n",
      "\n",
      "\n",
      "Query: Quy chế này quy định những gì và áp dụng cho đối tượng nào\n"
     ]
    }
   ],
   "source": [
    "\"\"\" MAIN \"\"\"\n",
    "\n",
    "with open(f\"Prompts/Docs_Prompt.txt\", \"r\", encoding=\"utf-8\") as file1:\n",
    "    docs_prompt = file1.read()\n",
    "\n",
    "with open(f\"Prompts/Docs_Prompt.txt\", \"r\", encoding=\"utf-8\") as file2:\n",
    "    natr_prompt = file2.read()\n",
    "\n",
    "print(\"<< Enter 'exit', 'quit', 'escape', 'bye' or Press ESC to exit >>\")\n",
    "print(\"Chatbot: Hello there! I'm here to help you!\\n\\n\")\n",
    "\n",
    "user_inputs = [\n",
    "    \"Quy chế này quy định những gì và áp dụng cho đối tượng nào\",\n",
    "    \"Sinh viên có thể được thi lại bao nhiêu lần?\",\n",
    "]\n",
    "\n",
    "i = 0\n",
    "while True:\n",
    "    try:\n",
    "        if i >= len(user_inputs):\n",
    "            user_input = \"exit\"\n",
    "        else:\n",
    "            user_input = user_inputs[i]\n",
    "\n",
    "        # user_input = input(\"You: \")\n",
    "\n",
    "        user_question = Embedding.preprocess_text(user_input)\n",
    "        if user_input.strip().lower() in [\"exit\", \"quit\", \"escape\", \"bye\", \"\"]:\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break\n",
    "\n",
    "        print(f\"Query: {user_question}\")\n",
    "\n",
    "        #Bước 1: Search\n",
    "        preliminary_results = Search.search_faiss_index(\n",
    "            MERGE = MERGE,\n",
    "            query= user_question,\n",
    "            embedd_model=EMBEDD_MODEL,\n",
    "            faiss_path=faiss_path,\n",
    "            mapping_path=mapping_path,\n",
    "            mapping_data=mapping_data,\n",
    "            device=device,\n",
    "            k=2,\n",
    "            min_score = 5,\n",
    "            batches = False,\n",
    "        )\n",
    "        print(preliminary_results)\n",
    "\n",
    "        # Bước 2: Rerank\n",
    "        reranked_results = Rerank.rerank_results(\n",
    "            query= user_question,\n",
    "            results=preliminary_results,\n",
    "            reranker_model=RERANK_MODEL,\n",
    "            device=device,\n",
    "            k=5,\n",
    "            batches = False,\n",
    "        )\n",
    "        print(reranked_results)\n",
    "        context = '\\n\\n'.join(item['text'] for item in reranked_results)\n",
    "        print(f\"\\nContext:\\n\")\n",
    "        print(context)\n",
    "\n",
    "        if (reranked_results):\n",
    "            system_prompt = docs_prompt\n",
    "            doc = True\n",
    "        else:\n",
    "            system_prompt = natr_prompt\n",
    "            doc = False\n",
    "\n",
    "        # # Bước 3: Generate Response\n",
    "        # response = Respond.respond_naturally(\n",
    "        #     user_question = user_question,\n",
    "        #     # results=reranked_results,\n",
    "        #     context = context,\n",
    "        #     system_prompt = system_prompt,\n",
    "        #     responser_model=RESPON_MODEL,\n",
    "        #     score_threshold=0.85,\n",
    "        #     max_results=3,\n",
    "        #     doc = doc,\n",
    "        #     gemini_api_key=API_KEY,\n",
    "        # )\n",
    "\n",
    "        # print(f\"\\nYou: {user_question}\")\n",
    "        # print(f\"Chatbot: {response}\\n\\n\")\n",
    "        \n",
    "        print(\"=\" * 200)\n",
    "        print(\"\\n\\n\")\n",
    "        i += 1\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nChatbot: Goodbye!\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
