{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import faiss\n",
    "import torch\n",
    "import logging\n",
    "from typing import List\n",
    "from typing import Any, Dict\n",
    "from sentence_transformers import util\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from RAGLibrary import Widgets, Define\n",
    "from RAGLibrary import CheckConstruct, CreateSchema, FaissConvert, Embedding, Search, Rerank, Respond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6ff5cefc964b7caf3cdfada155a460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='File:  ', index=1, layout=Layout(width='33%'), options=('Harvard_Regulati…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41219194067047a5a8ca0c1edd35040f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='contents', description='Data Key: ', layout=Layout(width='50%'), placeholder='Defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf3344b7a0b48bba65a9ea6641b44ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Model: ', index=1, layout=Layout(width='50%'), options=('Auto Model', 'Se…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "149ac887ab1446a1aec5f8a8706ec98a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Embedder: ', index=2, layout=Layout(width='90%'), options=('vinai/phobert-base', 'keepit…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa5be541b7b43b095ae0600932c1d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Searcher: ', index=1, layout=Layout(width='90%'), options=('faiss.IndexHNSWFlat', 'faiss…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e57a2d214f46bdbc0e6ccbb2c36a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Reranker: ', layout=Layout(width='90%'), options=('BAAI/bge-reranker-base',), value='BAA…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7e7310ba664522aa66b8a5bdf0470b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Response: ', layout=Layout(width='90%'), options=('gemini-2.0-flash-exp', 'vinai/PhoGPT-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba1f39384ef498e83aaeb452eef1e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='API Key:', index=4, layout=Layout(width='90%'), options=('AIzaSyDaHS-8h6GJkyVPhoX4svvYeB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546c69194cb1438fb35000186cfe2ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Max Level: ', index=4, layout=Layout(width='50%'), options=('0', '1', '2'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349da544dc71475da1eb46ff301a2e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62018997273e439a9623b572d56ed62e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='success', description='Save State', style=ButtonStyle()), Button(button_st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets_list = Widgets.create_name_form()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "force_download = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedder: VoVanPhuc/sup-SimCSE-VietNamese-phobert-base\n",
      "Searcher: faiss.IndexFlatIP\n",
      "Reranker: BAAI/bge-reranker-base\n",
      "Responer: gemini-2.0-flash-exp\n",
      "Data Key: contents\n",
      "Embe Key: embeddings\n",
      "Dcment  : ../Doc/HNMU_Regulations.docx\n",
      "Chunked : ../Data/HNMU_Regulations/QA_HNMU_Regulations_Chunks.json\n",
      "Database: ../Data/HNMU_Regulations/QA_HNMU_Regulations_Database.json\n",
      "Torch   : ../Data/HNMU_Regulations/QA_HNMU_Regulations_Embeds_Merge.pt\n",
      "Faiss   : ../Data/HNMU_Regulations/QA_HNMU_Regulations_Embeds_Merge.faiss\n",
      "Mapping : ../Data/HNMU_Regulations/QA_HNMU_Regulations_Embeds_Merge_mapping.json\n",
      "Map Data: ../Data/HNMU_Regulations/QA_HNMU_Regulations_Embeds_Merge_map_data.json\n",
      "Schema  : ../Data/HNMU_Regulations/QA_HNMU_Regulations_Schema.json\n",
      "Model   : Sentence Transformer\n",
      "Merge   : no_Merge\n",
      "API Key : AIzaSyBPjyMfHkS9OW3h7G0kmLSQkWQMfqfX5v0\n",
      "Word    : 200\n",
      "Level   : 4\n",
      "Level Values: ['Chương', 'Điều', 'Khoản', 'Nội dung']\n"
     ]
    }
   ],
   "source": [
    "config = Define.WidgetValues(widgets_list)\n",
    "\n",
    "dcmt_path = config[\"dcmt_path\"]\n",
    "base_folder = config[\"base_folder\"]\n",
    "base_path = config[\"base_path\"]\n",
    "chunks_base = config[\"chunks_base\"]\n",
    "json_file_path = config[\"json_file_path\"]\n",
    "schema_ex_path = config[\"schema_ex_path\"]\n",
    "embedding_path = config[\"embedding_path\"]\n",
    "torch_path = config[\"torch_path\"]\n",
    "faiss_path = config[\"faiss_path\"]\n",
    "mapping_path = config[\"mapping_path\"]\n",
    "mapping_data = config[\"mapping_data\"]\n",
    "\n",
    "FILE_TYPE = config[\"FILE_TYPE\"]\n",
    "DATA_KEY = config[\"DATA_KEY\"]\n",
    "EMBE_KEY = config[\"EMBE_KEY\"]\n",
    "SWITCH = config[\"SWITCH\"]\n",
    "EMBEDD_MODEL = config[\"EMBEDD_MODEL\"]\n",
    "SEARCH_EGINE = config[\"SEARCH_EGINE\"]\n",
    "RERANK_MODEL = config[\"RERANK_MODEL\"]\n",
    "RESPON_MODEL = config[\"RESPON_MODEL\"]\n",
    "MERGE = config[\"MERGE\"]\n",
    "API_KEY = config[\"API_KEY\"]\n",
    "\n",
    "WORD_LIMIT = config[\"WORD_LIMIT\"]\n",
    "LEVEL_INPUT = config[\"LEVEL_INPUT\"]\n",
    "LEVEL_VALUES = config[\"LEVEL_VALUES\"]\n",
    "\n",
    "SEARCH_ENGINE = faiss.IndexFlatIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer loaded successfully\n",
      "Using: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if (SWITCH == \"Auto Model\"):\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(EMBEDD_MODEL, force_download=force_download)\n",
    "        model = AutoModel.from_pretrained(EMBEDD_MODEL, force_download=force_download)\n",
    "        model = model.to(device)\n",
    "        print(\"Model and tokenizer loaded successfully\")\n",
    "    except Exception as e:\n",
    "        raise\n",
    "elif (SWITCH == \"Sentence Transformer\"):\n",
    "    try:\n",
    "        # model = SentenceTransformer(EMBEDD_MODEL).to(device)\n",
    "        model = SentenceTransformer(\"../../cached_model\")\n",
    "        print(\"SentenceTransformer loaded successfully\")\n",
    "    except Exception as e:\n",
    "        raise\n",
    "\n",
    "print(f\"Using: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PREPROCESS TEXT \"\"\"\n",
    "\n",
    "def preprocess_text(text):\n",
    "    import re\n",
    "    if isinstance(text, list):\n",
    "        return [preprocess_text(t) for t in text]\n",
    "    if isinstance(text, str):\n",
    "        text = text.strip()\n",
    "        text = re.sub(r'[^\\w\\s\\(\\)\\.\\,\\;\\:\\-–]', '', text)\n",
    "        text = re.sub(r'[ ]{2,}', ' ', text)\n",
    "        return text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" CREATE EMBEDDING \"\"\"\n",
    "\n",
    "def create_embedding(texts, batch_size=32):\n",
    "    try:\n",
    "        embeddings = model.encode(texts, batch_size=batch_size, convert_to_tensor=True, device=device)\n",
    "        return embeddings\n",
    "    except RuntimeError as e:\n",
    "        if \"CUDA out of memory\" in str(e):\n",
    "            print(\"VRAM overflow. Switching to CPU.\")\n",
    "            model.to(\"cpu\")\n",
    "            return model.encode(texts, batch_size=batch_size, convert_to_tensor=True, device=\"cpu\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadEmbedding(embedding_path: str, device, DATA_KEY: str = \"content\", EMBE_KEY: str = \"data_embeddings\", field_keys: List[str] = [\"Câu hỏi\", \"Câu trả lời\", \"Câu hỏi Embedding\"]) -> Dict[str, Any]:\n",
    "    result = {}\n",
    "    print(f\"\\nĐang tải embedding từ {embedding_path}\\n\")\n",
    "    try:\n",
    "        data = torch.load(embedding_path, map_location=\"cpu\", weights_only=False)\n",
    "        \n",
    "        print(f\"Các key có sẵn: {list(data.keys())}\")\n",
    "\n",
    "        content = []\n",
    "        if isinstance(data, dict) and DATA_KEY in data:\n",
    "            content = data[DATA_KEY]\n",
    "            print(f\"Số mục trong '{DATA_KEY}': {len(content)}\")\n",
    "        else:\n",
    "            print(f\"Lỗi: File .pt không có key '{DATA_KEY}' hoặc không đúng định dạng.\")\n",
    "        \n",
    "        if not content:\n",
    "            print(\"Lỗi: File trống.\")\n",
    "        else:\n",
    "            for key in field_keys:\n",
    "                data_list = [item[key] for item in content if key in item]\n",
    "                if data_list:\n",
    "                    if key.lower().find(\"embedding\") != -1 and isinstance(data_list[0], (list, torch.Tensor)):\n",
    "                        result[key] = torch.tensor(data_list, dtype=torch.float32).to(device)\n",
    "                        print(f\"Đã tải '{key}' với kích thước: {result[key].shape}\")\n",
    "                    else:\n",
    "                        result[key] = data_list\n",
    "                        print(f\"Đã tải '{key}' với số mục: {len(data_list)}\")\n",
    "                else:\n",
    "                    print(f\"Cảnh báo: Không tìm thấy '{key}' trong '{DATA_KEY}'.\")\n",
    "                \n",
    "                if key not in result and key.lower().find(\"embedding\") != -1 and EMBE_KEY in data:\n",
    "                    embed_data = data[EMBE_KEY]\n",
    "                    if isinstance(embed_data, (list, torch.Tensor)) and len(embed_data) > 0:\n",
    "                        result[key] = torch.tensor(embed_data, dtype=torch.float32).to(device)\n",
    "                        print(f\"Đã tải '{key}' từ '{EMBE_KEY}' với kích thước: {result[key].shape}\")\n",
    "        \n",
    "        for key in field_keys:\n",
    "            if key in result:\n",
    "                if isinstance(result[key], torch.Tensor):\n",
    "                    print(f\"Số '{key}': {result[key].shape[0]}\")\n",
    "                else:\n",
    "                    print(f\"Số '{key}': {len(result[key])}\")\n",
    "            else:\n",
    "                print(f\"Lỗi: Không tải được '{key}'.\")\n",
    "        \n",
    "    except (KeyError, ValueError, RuntimeError) as e:\n",
    "        print(f\"Lỗi khi tải embedding: {e}\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_questions = []\n",
    "qa_answers = []\n",
    "qa_question_embeddings = None\n",
    "required_fields = [\"Câu hỏi\", \"Câu trả lời\", \"Câu hỏi Embedding\"]\n",
    "\n",
    "data = {}\n",
    "if os.path.exists(embedding_path):\n",
    "    data = LoadEmbedding(\n",
    "        embedding_path=embedding_path,\n",
    "        device=device,\n",
    "        DATA_KEY=DATA_KEY,\n",
    "        EMBE_KEY=EMBE_KEY,\n",
    "        field_keys=required_fields\n",
    "    )\n",
    "\n",
    "if data:\n",
    "    print(\"\\nDữ liệu trả về:\")\n",
    "    for key in required_fields:\n",
    "        if key in data:\n",
    "            if isinstance(data[key], torch.Tensor):\n",
    "                print(f\"{key}: Tensor với kích thước {data[key].shape}\")\n",
    "            else:\n",
    "                print(f\"{key}: {len(data[key])} mục\")\n",
    "        else:\n",
    "            print(f\"Lỗi: Không tìm thấy '{key}' trong dữ liệu trả về.\")\n",
    "\n",
    "    qa_questions = data.get(\"Câu hỏi\", [])\n",
    "    qa_answers = data.get(\"Câu trả lời\", [])\n",
    "    qa_question_embeddings = data.get(\"Câu hỏi Embedding\")\n",
    "    if qa_question_embeddings is not None and isinstance(qa_question_embeddings, torch.Tensor):\n",
    "        print(f\"Kích thước của 'Câu hỏi Embedding': {qa_question_embeddings.shape}\")\n",
    "    else:\n",
    "        print(\"Lỗi: Không tìm thấy 'Câu hỏi Embedding' trong dữ liệu trả về.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_cache = {}\n",
    "def find_best_answer(user_question):\n",
    "    user_question = preprocess_text(user_question)\n",
    "    if user_question in question_cache:\n",
    "        user_embedding = question_cache[user_question]\n",
    "    else:\n",
    "        user_embedding = create_embedding([user_question])[0].to(device)\n",
    "        question_cache[user_question] = user_embedding\n",
    "    print(\"qa_question_embeddings:\", qa_question_embeddings)\n",
    "\n",
    "    similarities = util.pytorch_cos_sim(user_embedding, qa_question_embeddings)[0]\n",
    "    torch.cuda.empty_cache()\n",
    "    threshold = max(0.7, similarities.max().item() * 0.9)\n",
    "    matched_indices = torch.where(similarities >= threshold)[0]\n",
    "    \n",
    "    if len(matched_indices) > 0:\n",
    "        responses = sorted(\n",
    "            [(qa_answers[idx.item()], similarities[idx].item()) for idx in matched_indices],\n",
    "            key=lambda x: x[1], reverse=True\n",
    "        )[:5]\n",
    "        return responses\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< Enter 'exit', 'quit', 'escape', 'bye' or Press ESC to exit >>\n",
      "Chatbot: Hello there! I'm here to help you =))\n",
      "qa_question_embeddings: None\n",
      "user_embedding: tensor([ 1.7324e-01, -8.6638e-02, -4.6058e-01,  3.5518e-01, -1.2872e-01,\n",
      "         3.9851e-01,  1.7922e-01,  5.2207e-01, -3.6000e-01,  3.6407e-02,\n",
      "         7.5967e-02,  1.5796e-01, -3.5858e-01,  6.8878e-02, -4.5556e-01,\n",
      "         9.4099e-02,  4.6090e-01,  2.8570e-01,  7.0356e-01, -3.0198e-03,\n",
      "        -1.8586e-01, -1.6834e-01,  2.1587e-01,  9.3667e-01, -6.0581e-01,\n",
      "         8.7358e-02, -3.8642e-01,  1.0213e+00,  2.7402e-01,  7.6881e-02,\n",
      "        -4.7702e-01, -1.2053e-01, -1.6456e-01,  2.7625e-01,  2.3776e-01,\n",
      "         1.2055e-01, -3.1143e-01,  5.9284e-01, -3.6907e-01,  3.4606e-01,\n",
      "        -1.6581e-01,  5.6713e-02, -5.7945e-01, -4.1051e-02, -2.8173e-01,\n",
      "         2.9706e-01,  4.5443e-01,  2.9062e-02,  3.7175e-01,  7.4290e-02,\n",
      "         1.4528e-01,  1.5266e-01,  9.4764e-02,  7.5575e-02, -1.4425e-01,\n",
      "        -3.9950e-01, -6.6262e-01, -1.0661e-01,  1.9031e-01,  6.2703e-01,\n",
      "         3.1788e-01, -2.0755e-01,  2.1578e-02, -5.6387e-03,  2.2531e-01,\n",
      "        -1.7364e-01, -1.7527e-01,  3.5220e-01, -1.1202e-01, -3.1571e-01,\n",
      "        -4.3219e-01,  4.1254e-01,  5.0208e-02,  2.0404e-01,  2.4899e-01,\n",
      "         2.6702e-01, -3.6916e-01,  2.1275e-01,  1.9040e-01,  2.0602e-01,\n",
      "         1.0490e+00, -1.4957e-01,  2.8366e-01,  1.7765e-01, -3.0803e-01,\n",
      "        -2.7669e-01, -2.9359e-01,  2.3223e-01, -4.9890e-01, -2.9949e-02,\n",
      "        -5.2150e-02,  2.8916e-01, -2.8651e-01,  3.3720e-01, -7.2187e-02,\n",
      "         1.6826e-02,  2.9372e-01,  3.0633e-01,  4.9143e-01,  1.8992e-01,\n",
      "        -2.8544e-01, -4.4398e-02,  1.5396e+00,  1.8356e-01, -8.7872e-02,\n",
      "         1.5504e-01,  3.5085e-01,  5.1954e-02,  5.6560e-01,  8.8270e-01,\n",
      "         9.6635e-01, -1.4608e-01,  4.3724e-01, -1.3459e-01, -4.5571e-01,\n",
      "         2.7182e-01, -2.1856e-01,  4.2216e-01, -2.2659e-02, -7.0464e-02,\n",
      "        -2.4958e-01,  1.8800e-01, -2.2220e-01, -1.1103e-01,  1.8574e-01,\n",
      "        -2.7606e-01,  6.1704e-02, -2.8121e-02,  2.7850e-01,  2.5110e-01,\n",
      "         3.7487e-01, -1.2362e-01,  2.1925e-01,  4.0585e-01, -3.9727e-01,\n",
      "         7.8099e-01,  2.4108e-01, -4.6754e-01, -2.8638e-01, -8.4647e-01,\n",
      "        -5.0779e-01, -2.2022e-02, -2.2930e-01,  2.1018e-01, -2.2577e-01,\n",
      "        -6.7510e-01,  3.5251e-01, -2.2159e-01, -1.3169e-01,  1.4060e-01,\n",
      "         2.0550e-01,  6.2691e-01,  2.5668e-01, -2.8860e-01,  2.7953e-01,\n",
      "        -4.9932e-01,  6.2437e-01,  1.1060e-01,  1.7681e-01,  8.8701e-01,\n",
      "         1.7898e-03,  3.3983e-01,  5.0867e-02,  3.9937e-01,  1.7728e-01,\n",
      "         8.9813e-04, -6.1348e-01, -3.7281e-01,  1.9545e-01, -3.0537e-01,\n",
      "         1.1510e-01,  1.9252e-01,  2.0141e-01,  3.5673e-01,  2.1838e-01,\n",
      "         1.8290e-01,  5.1225e-01,  2.2087e-01,  2.3822e-01, -1.8482e-01,\n",
      "         5.0549e-01, -4.8042e-01,  5.0080e-01,  6.5174e-02,  2.2202e-01,\n",
      "         2.3418e-01,  1.1945e-01, -7.0534e-02,  3.0318e-01,  1.2158e-02,\n",
      "         5.9434e-01,  5.9346e-01, -6.2828e-01, -3.0727e-01, -9.9777e-02,\n",
      "        -1.7181e-01,  3.9988e-01,  3.2749e-01, -1.8299e-01,  1.8627e-01,\n",
      "        -2.4733e-02,  3.8605e-01, -1.4085e-01, -1.0475e+00,  1.4448e-01,\n",
      "         2.1105e-01, -3.7002e-01, -1.2135e-01,  5.3337e-01,  5.4630e-01,\n",
      "        -6.7695e-02,  5.9633e-01,  2.4144e-01, -4.7722e-01,  1.4144e-01,\n",
      "        -1.0546e-01,  2.7287e-01, -5.3946e-01, -7.7174e-01, -1.8352e-01,\n",
      "        -2.5308e-01,  4.8073e-02, -7.5542e-01, -3.7796e-01,  9.5401e-01,\n",
      "        -4.6028e-01,  7.5085e-01,  1.1762e-01, -2.3764e-01,  7.8556e-02,\n",
      "         1.1045e-01, -8.0669e-02,  3.0747e-01,  3.4178e-01, -6.8112e-01,\n",
      "        -5.7621e-01,  5.4337e-01,  1.5471e-01, -5.8534e-01, -9.1238e-01,\n",
      "         2.1776e-02, -6.9348e-02, -3.2992e-01,  6.6730e-02,  4.4865e-02,\n",
      "         3.9873e-01, -3.5573e-02,  1.5896e-01, -1.4124e-01,  9.2294e-02,\n",
      "         3.5442e-02,  3.5213e-01,  3.4929e-01, -1.3755e-02, -1.2585e-01,\n",
      "         3.1373e-01, -3.6994e-01, -2.7301e-02, -5.6252e-01,  1.8610e-01,\n",
      "        -4.2488e-01,  2.6190e-01, -8.8291e-01, -1.9824e-01, -3.1442e-01,\n",
      "        -9.8912e-02,  3.1616e-01, -1.2401e-02, -3.9475e-01,  1.0171e-01,\n",
      "        -1.6976e-01,  3.6805e-01,  1.1042e-01, -6.2028e-01, -2.2617e-01,\n",
      "        -3.9467e-01, -2.2145e-01,  4.7932e-01,  4.5451e-01,  5.5539e-01,\n",
      "         2.9252e-01, -4.9025e-01,  4.1352e-01, -4.4775e-01,  1.7685e-01,\n",
      "         2.7061e-04,  2.3041e-01,  2.2468e-01, -2.9056e-01, -2.4142e-01,\n",
      "         6.9477e-01, -1.2080e-01,  1.9937e-01, -2.9769e-01, -3.5120e-01,\n",
      "        -5.9362e-02, -2.6366e-01, -4.5407e-01,  1.7021e-01,  6.8305e-01,\n",
      "         3.2001e-02,  2.3098e-02,  4.2558e-01,  1.0655e-01,  7.8433e-01,\n",
      "         3.1505e-02,  3.8980e-01, -4.7206e-01,  1.3372e-01, -7.4020e-01,\n",
      "        -4.3299e-01, -9.9097e-02, -3.4648e-02,  1.9324e-01, -3.9093e-02,\n",
      "         4.2512e-01, -4.8445e-01, -1.1757e-01,  4.8131e-01, -3.9354e-01,\n",
      "         1.8784e-01, -3.4106e-01, -5.7633e-01,  1.7654e-01, -9.6218e-01,\n",
      "        -5.6044e-01,  5.6067e-01,  1.1438e+00,  2.4101e-01, -2.9938e-01,\n",
      "        -1.1025e-01,  5.7549e-02,  4.8437e-02,  3.0383e-01,  2.4926e-01,\n",
      "        -6.1713e-01, -4.9678e-01,  1.0640e-01, -7.3216e-01, -3.6828e-01,\n",
      "         2.8819e-01,  2.9197e-01, -2.3353e-02,  6.4704e-01,  8.4537e-01,\n",
      "        -2.6603e-01,  1.8498e-01, -1.9979e-01, -4.7907e-01, -3.1580e-02,\n",
      "         3.5079e-01,  2.6648e-01,  4.7761e-01, -1.0384e-02,  1.8626e-01,\n",
      "        -7.7253e-01,  1.2926e-01, -4.8706e-03,  2.3896e-01,  5.7199e-01,\n",
      "         8.4228e-01, -8.9348e-02, -2.7378e-02, -2.4831e-01,  7.7570e-02,\n",
      "        -6.4701e-01,  1.2385e-01,  4.9959e-01, -3.3985e-01, -7.8292e-01,\n",
      "        -2.2738e-01, -2.4172e-01,  4.8299e-02,  7.0917e-03,  1.6832e-01,\n",
      "        -2.6618e-01,  1.1072e-01,  9.7934e-02,  5.3222e-02, -9.6495e-02,\n",
      "         4.3784e-02,  7.1155e-01,  1.5043e-01, -1.2591e-01, -8.8315e-02,\n",
      "         1.6261e-01, -6.7847e-01,  1.4289e-01, -1.1760e-02, -3.9970e-02,\n",
      "        -3.1683e-01,  4.7112e-01,  2.7191e-01, -4.1838e-02, -1.6145e-01,\n",
      "        -5.1710e-01,  7.9453e-03, -1.8643e-01, -9.6203e-01, -1.8732e-01,\n",
      "         3.0854e-01, -4.5155e-01,  1.8110e-01, -5.2809e-01,  3.1091e-01,\n",
      "        -3.7567e-01,  9.5358e-01,  4.8413e-01, -1.7431e-01, -8.5622e-02,\n",
      "        -3.9143e-01,  1.6799e+00,  4.7760e-01,  5.6095e-01, -8.1909e-02,\n",
      "         2.3206e-02,  4.5013e-02,  2.6053e-01,  7.9308e-01,  1.0502e-01,\n",
      "        -1.6909e-01, -4.3948e-01, -1.6871e-01, -3.8807e-01, -2.2154e-01,\n",
      "         2.2143e-01,  1.1990e-01, -9.7597e-02,  1.6096e-01, -9.5497e-02,\n",
      "         4.2622e-01,  3.3738e-01,  5.9002e-01, -9.1793e-01,  5.9302e-02,\n",
      "         3.6330e-01,  1.1656e-01, -3.4327e-01,  5.1778e-01, -6.7174e-01,\n",
      "         1.9940e-01, -1.1906e-01,  1.2344e-01, -2.8803e-01,  6.1120e-01,\n",
      "         2.4860e-01, -3.1906e-02,  2.2519e-01, -1.8666e-01,  5.2093e-01,\n",
      "        -4.7503e-02, -2.9405e-02,  9.4039e-02, -4.7478e-02,  1.3075e-01,\n",
      "         9.9417e-01,  4.1162e-01,  3.7641e-01, -1.9618e-01, -3.2980e-01,\n",
      "        -6.1384e-02,  4.2516e-01,  9.0902e-01,  4.3974e-01, -1.7992e-01,\n",
      "        -2.7015e-02,  3.3241e-02, -2.1516e-01, -1.1354e-01,  4.5770e-01,\n",
      "         2.5340e-01,  1.0181e-01,  9.8246e-01, -4.8782e-01, -4.0753e-01,\n",
      "        -1.5643e-01,  8.9724e-02,  3.1582e-01,  2.2972e-01, -2.0908e-01,\n",
      "         2.1541e-01, -7.8759e-01, -2.9137e-01, -1.1375e-01, -4.4444e-01,\n",
      "         3.6967e-02, -5.8524e-01, -1.9479e-01,  3.0312e-02,  5.3141e-02,\n",
      "         5.9705e-01, -5.2836e-01, -2.0452e-01, -5.9601e-01,  8.7172e-02,\n",
      "         2.0117e-01, -7.1164e-02,  2.1415e-01,  1.1581e-01, -3.6926e-01,\n",
      "         5.6320e-01,  1.6204e-01,  1.0868e+00,  3.1887e-01,  2.9263e-01,\n",
      "        -6.1250e-01,  7.7950e-02, -3.8405e-01, -8.4317e-02, -3.7601e-01,\n",
      "        -5.7021e-01,  1.4654e-01, -7.2597e-02, -5.2080e-01, -4.9355e-01,\n",
      "         2.0883e-01, -6.0888e-01, -9.5187e-01, -2.4490e-01, -3.2645e-01,\n",
      "         3.3342e-01,  4.5941e-02, -2.6765e-01, -2.8118e-01, -4.8182e-01,\n",
      "         1.2969e-02, -4.1837e-01, -3.6614e-01, -1.3669e-01, -4.1187e-01,\n",
      "        -2.3029e-01, -1.9026e-01,  2.9510e-01,  3.3307e-01,  1.1395e-01,\n",
      "         6.3612e-02, -5.2194e-01, -4.4468e-02, -2.4200e-01, -5.4752e-02,\n",
      "        -3.3151e-01, -3.0911e-01, -1.1419e-01,  1.4072e-01,  5.3385e-01,\n",
      "        -2.2376e-01,  3.7852e-01,  2.4509e-01, -1.4359e-01, -4.3772e-01,\n",
      "         1.9597e-01, -1.3545e-01,  1.7968e-01, -9.5663e-02, -8.7698e-02,\n",
      "        -3.1165e-02,  4.8419e-01, -2.6167e-01,  3.4205e-01,  2.2746e-01,\n",
      "         5.6813e-02,  3.7789e-02, -2.9150e-01,  9.0433e-02, -8.4080e-03,\n",
      "         7.3329e-01,  4.9215e-01,  7.7960e-03,  3.6367e-01,  2.7794e-03,\n",
      "        -2.9486e-01,  4.7965e-01, -1.9581e-01, -1.1691e-01, -2.0916e-01,\n",
      "         3.7067e-01, -1.1414e-01,  7.7443e-02,  4.5105e-01, -2.1264e-03,\n",
      "        -2.8975e-01, -1.5855e-01,  4.2620e-02, -4.5397e-02,  5.5179e-01,\n",
      "         3.9279e-01, -2.4868e-01, -1.2446e-01, -2.7363e-01,  6.6103e-01,\n",
      "         1.9761e+00,  4.2267e-01, -2.8182e-01, -1.9889e-01,  7.5812e-01,\n",
      "         3.9471e-01,  3.3904e-01,  3.3635e-01, -1.7810e-01,  1.0669e-01,\n",
      "        -1.9319e-01, -4.3542e-02,  6.7444e-02,  5.1257e-02, -7.5349e-02,\n",
      "         2.7542e-01, -2.6461e-01,  7.2446e-02,  4.5237e-02, -3.3637e-01,\n",
      "        -3.4026e-03, -2.0950e-01,  1.3921e-01, -3.5092e-01,  7.2354e-02,\n",
      "        -1.0520e-01,  8.3317e-01, -2.9146e-01, -4.7717e-01,  9.3404e-03,\n",
      "         3.0257e-02,  6.1614e-02, -6.2736e-01, -1.6355e-01,  3.3886e-01,\n",
      "         7.2387e-01, -3.1834e-01,  5.1663e-02,  1.2562e-01, -3.6491e-01,\n",
      "         1.5916e-01, -4.6093e-01, -4.3614e-01,  1.9207e-01, -2.4699e-01,\n",
      "         5.9266e-02, -3.7451e-01,  3.3587e-02, -1.9625e-02,  7.3860e-02,\n",
      "        -2.9759e-01, -2.7246e-01,  1.8532e-01, -2.9393e-01,  2.6206e-02,\n",
      "         1.8019e-01,  1.9002e-01,  1.4290e-01,  5.0517e-01, -7.2739e-01,\n",
      "        -5.2286e-01,  2.9915e-01, -1.9820e-01, -1.0160e-01, -4.4217e-01,\n",
      "        -4.2197e-02, -3.0824e-01, -3.0761e-01,  5.3836e-01, -5.1042e-02,\n",
      "        -2.8685e-02, -3.2681e-01,  6.0484e-01,  3.7760e-01,  5.0550e-01,\n",
      "         3.8832e-01,  4.9163e-01,  1.3474e-02, -5.2328e-02,  5.5892e-01,\n",
      "        -3.6733e-02,  2.4863e-01, -2.4174e-01,  5.6911e-01,  2.9366e-01,\n",
      "        -1.6301e-01,  4.4538e-03,  3.5066e-01, -2.1315e-01,  1.8984e-02,\n",
      "        -4.4053e-03,  3.8796e-02,  3.9460e-02,  1.9036e-01, -6.7826e-01,\n",
      "         2.1306e-01,  4.4540e-01,  1.4063e-01, -6.4427e-01,  9.6336e-02,\n",
      "        -8.8275e-02, -1.0798e-01,  1.3036e-01,  5.7604e-01,  2.8741e-01,\n",
      "         2.2163e-01,  3.1668e-01,  1.5307e-01,  9.7354e-02, -2.2118e-01,\n",
      "         1.4838e-01,  1.8904e-01,  4.9100e-01,  1.7685e-01,  4.2242e-02,\n",
      "        -2.4685e-01, -8.1600e-02,  2.8473e-01,  9.3605e-02,  4.3881e-01,\n",
      "        -1.3320e-01, -4.2147e-01,  3.6204e-01,  3.4908e-01,  6.8145e-01,\n",
      "        -5.8440e-01,  2.1471e-01, -3.0751e-01, -2.0158e-01,  1.4897e-01,\n",
      "        -1.5670e-01,  7.5909e-02, -2.0948e-01,  3.7341e-01,  4.0798e-01,\n",
      "         4.0480e-01,  4.4207e-01,  8.8156e-01, -4.8790e-02,  6.7735e-01,\n",
      "         2.1751e-01, -5.3389e-01, -4.4666e-01,  1.7288e-01,  6.8831e-02,\n",
      "         2.0270e-01, -6.1390e-01,  7.1592e-01,  1.6588e-01, -1.1216e-01,\n",
      "         2.2512e-01, -2.5682e-02,  5.7427e-01, -1.1602e-01,  9.1826e-02,\n",
      "         3.9832e-01,  5.0114e-01, -3.2835e-01,  3.0205e-02, -2.0130e-01,\n",
      "         2.4394e-01, -8.6515e-02, -1.6919e-01,  3.1663e-01,  8.1540e-02,\n",
      "        -2.0125e-01, -1.5048e-01,  3.8736e-01, -6.9776e-01, -2.6505e-01,\n",
      "         1.1216e-01,  1.5126e-01,  5.4984e-01,  8.2553e-02,  3.0235e-02,\n",
      "         1.0695e-02,  8.0778e-02,  1.5548e-01], device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Could not infer dtype of NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mChatbot: Goodbye!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m responses = \u001b[43mfind_best_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mYou: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_input.strip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m responses:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mfind_best_answer\u001b[39m\u001b[34m(user_question)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mqa_question_embeddings:\u001b[39m\u001b[33m\"\u001b[39m, qa_question_embeddings)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33muser_embedding:\u001b[39m\u001b[33m\"\u001b[39m, user_embedding)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m similarities = \u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpytorch_cos_sim\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqa_question_embeddings\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m     13\u001b[39m torch.cuda.empty_cache()\n\u001b[32m     14\u001b[39m threshold = \u001b[38;5;28mmax\u001b[39m(\u001b[32m0.7\u001b[39m, similarities.max().item() * \u001b[32m0.9\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Orias.ASUS\\miniconda3\\envs\\rag\\Lib\\site-packages\\sentence_transformers\\util.py:89\u001b[39m, in \u001b[36mpytorch_cos_sim\u001b[39m\u001b[34m(a, b)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpytorch_cos_sim\u001b[39m(a: Tensor, b: Tensor) -> Tensor:\n\u001b[32m     79\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[33;03m    Computes the cosine similarity between two tensors.\u001b[39;00m\n\u001b[32m     81\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     87\u001b[39m \u001b[33;03m        Tensor: Matrix with res[i][j] = cos_sim(a[i], b[j])\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcos_sim\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Orias.ASUS\\miniconda3\\envs\\rag\\Lib\\site-packages\\sentence_transformers\\util.py:104\u001b[39m, in \u001b[36mcos_sim\u001b[39m\u001b[34m(a, b)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     94\u001b[39m \u001b[33;03mComputes the cosine similarity between two tensors.\u001b[39;00m\n\u001b[32m     95\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    101\u001b[39m \u001b[33;03m    Tensor: Matrix with res[i][j] = cos_sim(a[i], b[j])\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    103\u001b[39m a = _convert_to_batch_tensor(a)\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m b = \u001b[43m_convert_to_batch_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m a_norm = normalize_embeddings(a)\n\u001b[32m    107\u001b[39m b_norm = normalize_embeddings(b)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Orias.ASUS\\miniconda3\\envs\\rag\\Lib\\site-packages\\sentence_transformers\\util.py:73\u001b[39m, in \u001b[36m_convert_to_batch_tensor\u001b[39m\u001b[34m(a)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_convert_to_batch_tensor\u001b[39m(a: \u001b[38;5;28mlist\u001b[39m | np.ndarray | Tensor) -> Tensor:\n\u001b[32m     64\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[33;03m    Converts the input data to a tensor with a batch dimension.\u001b[39;00m\n\u001b[32m     66\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     71\u001b[39m \u001b[33;03m        Tensor: The converted tensor with a batch dimension.\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     a = \u001b[43m_convert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m     a = _convert_to_batch(a)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Orias.ASUS\\miniconda3\\envs\\rag\\Lib\\site-packages\\sentence_transformers\\util.py:44\u001b[39m, in \u001b[36m_convert_to_tensor\u001b[39m\u001b[34m(a)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[33;03mConverts the input `a` to a PyTorch tensor if it is not already a tensor.\u001b[39;00m\n\u001b[32m     36\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m \u001b[33;03m    Tensor: The converted tensor.\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, Tensor):\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     a = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[31mRuntimeError\u001b[39m: Could not infer dtype of NoneType"
     ]
    }
   ],
   "source": [
    "print(\"<< Enter 'exit', 'quit', 'escape', 'bye' or Press ESC to exit >>\")\n",
    "print(\"Chatbot: Hello there! I'm here to help you =))\")\n",
    "\n",
    "user_inputs = [\n",
    "    \"Sinh viên có thể được thi lại bao nhiêu lần?\",\n",
    "    \"Sinh viên chưa đăng ki học được trên cổng thông tin thì có thể học bổ sung không\",\n",
    "]\n",
    "\n",
    "i = 0\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        if i >= len(user_inputs):\n",
    "            user_input = \"exit\"\n",
    "        else:\n",
    "            user_input = user_inputs[i]\n",
    "    \n",
    "        # user_input = input(\"You: \")\n",
    "        if user_input.strip().lower() in [\"exit\", \"quit\", \"escape\", \"bye\", \"\"]:\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break\n",
    "\n",
    "        responses = find_best_answer(user_input)\n",
    "\n",
    "        print(f\"You: {user_input.strip()}\")\n",
    "        if responses:\n",
    "            print(\"Chatbot:\")\n",
    "            for i, (response, score) in enumerate(responses, 1):\n",
    "                print(f\"{i}. [{score:.4f}] {response}\")\n",
    "        else:\n",
    "            print(\"Chatbot: Sorry I don't know the answer to that question =))\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nChatbot: Goodbye!\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
