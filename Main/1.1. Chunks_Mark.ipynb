{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import torch\n",
        "import faiss\n",
        "import logging\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from RAGLibrary import A0_Widgets, A1_Define\n",
        "from RAGLibrary import B1_ExtractData, B2_MergeData, B3_Chunking\n",
        "from RAGLibrary import C1_CreateSchema, C2_Embedding, C3_CheckConstruct\n",
        "from RAGLibrary import D0_FaissConvert, D1_Search, D2_Rerank, D3_Respond"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
        "widgets_list = A0_Widgets.create_name_form()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = A1_Define.WidgetValues(widgets_list)\n",
        "\n",
        "data_foler = config[\"data_folder\"]\n",
        "dcmt_path = config[\"dcmt_path\"]\n",
        "base_folder = config[\"base_folder\"]\n",
        "base_path = config[\"base_path\"]\n",
        "chunks_base = config[\"chunks_base\"]\n",
        "json_file_path = config[\"json_file_path\"]\n",
        "schema_ex_path = config[\"schema_ex_path\"]\n",
        "embedding_path = config[\"embedding_path\"]\n",
        "torch_path = config[\"torch_path\"]\n",
        "faiss_path = config[\"faiss_path\"]\n",
        "mapping_path = config[\"mapping_path\"]\n",
        "mapping_data = config[\"mapping_data\"]\n",
        "\n",
        "FILE_TYPE = config[\"FILE_TYPE\"]\n",
        "DATA_KEY = config[\"DATA_KEY\"]\n",
        "EMBE_KEY = config[\"EMBE_KEY\"]\n",
        "SWITCH = config[\"SWITCH\"]\n",
        "EMBEDD_MODEL = config[\"EMBEDD_MODEL\"]\n",
        "SEARCH_EGINE = config[\"SEARCH_EGINE\"]\n",
        "RERANK_MODEL = config[\"RERANK_MODEL\"]\n",
        "RESPON_MODEL = config[\"RESPON_MODEL\"]\n",
        "MERGE = config[\"MERGE\"]\n",
        "API_KEY = config[\"API_KEY\"]\n",
        "\n",
        "WORD_LIMIT = config[\"WORD_LIMIT\"]\n",
        "LEVEL_INPUT = config[\"LEVEL_INPUT\"]\n",
        "LEVEL_VALUES = config[\"LEVEL_VALUES\"]\n",
        "\n",
        "SEARCH_ENGINE = faiss.IndexFlatIP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = dcmt_path\n",
        "Contents = LEVEL_VALUES[-1] if LEVEL_VALUES else None\n",
        "print(Contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXTRACT DATA\n",
        "text_data = B1_ExtractData.extractData(dcmt_path)\n",
        "# text_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "BASE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ADD CHUNKS\n",
        "def add_chunk(chunks, content):\n",
        "    if content[\"Chương\"] and content[Contents]:\n",
        "        content[\"Index\"] += 1\n",
        "        chunks.append(content.copy())\n",
        "        content[Contents] = []\n",
        "        \n",
        "def is_chapter(text):\n",
        "    text = text.strip()\n",
        "    return bool(re.match(r\"^Chương\\s*[IVXLCDM\\d]+\\b\", text, re.IGNORECASE))\n",
        "\n",
        "def is_article(text):\n",
        "    text = text.strip()\n",
        "    return bool(re.match(r\"^Điều\\s+([IVXLCDM\\d]+)\\.\\s*(.+)\", text, re.IGNORECASE))\n",
        "\n",
        "def is_clause(text):\n",
        "    text = text.strip()\n",
        "    return bool(re.match(r\"^\\d+\\.\\s+.+\", text))\n",
        "\n",
        "def is_content(text):\n",
        "    text = text.strip()\n",
        "    return bool(re.match(r'^([-+*•●◦○] )|([a-zA-Z\\-\\+\\*]+[.)\\]:] )|(\\(\\w+\\) )', text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MAIN FUNCTION\n",
        "def main(text_data):\n",
        "    chunks = []\n",
        "    content = {\"Index\": 0, \"Chương\": None, \"Điều\": None, \"Khoản\": None, Contents: []}\n",
        "    i = 0\n",
        "    while i < len(text_data):\n",
        "        chunk = text_data[i][\"text\"]\n",
        "\n",
        "        if is_chapter(chunk):\n",
        "            if i + 1 < len(text_data):\n",
        "                chunk += f\": {text_data[i + 1]['text']}\"\n",
        "            add_chunk(chunks, content)\n",
        "            content[\"Chương\"] = chunk\n",
        "            content[\"Điều\"] = None\n",
        "            content[\"Khoản\"] = None \n",
        "            i += 1\n",
        "\n",
        "        elif is_article(chunk):\n",
        "            match = re.match(r\"^(Điều\\s*[IVXLCDM\\d]+)\\.\\s*(.+)\", chunk, re.IGNORECASE)\n",
        "            if content[\"Chương\"]:\n",
        "                if match:\n",
        "                    chunk = f\"{match.group(1)}: {match.group(2)}\"\n",
        "                add_chunk(chunks, content)\n",
        "                content[\"Điều\"] = chunk\n",
        "                content[\"Khoản\"] = None \n",
        "        \n",
        "        elif is_clause(chunk):\n",
        "            match = re.match(r\"^(\\d+)\\.\\s*(.+)\", chunk)\n",
        "            if content[\"Chương\"]:\n",
        "                if match:\n",
        "                    clause_number = match.group(1)\n",
        "                    clause_content = match.group(2)\n",
        "\n",
        "                    if i + 1 < len(text_data) and is_content(text_data[i + 1][\"text\"]):\n",
        "                        chunk = f\"Khoản {clause_number}: {clause_content}\"\n",
        "                        add_chunk(chunks, content)\n",
        "                        content[\"Khoản\"] = chunk\n",
        "                    else:\n",
        "                        chunk = f\"Khoản {clause_number}\"\n",
        "                        add_chunk(chunks, content)\n",
        "                        content[\"Khoản\"] = chunk\n",
        "\n",
        "                        chunk = clause_content\n",
        "                        content[Contents].append(chunk)\n",
        "                else: \n",
        "                    print(chunk)\n",
        "\n",
        "        elif is_content(chunk):\n",
        "            match = re.match(r'^([-+*•●◦○a-zA-Z\\-\\+\\*]+[.)\\]:] )(\\s.+)', chunk)\n",
        "            if content[\"Chương\"]:\n",
        "                if match:\n",
        "                    chunk = match.group(2)\n",
        "                content[Contents].append(chunk)\n",
        "        i += 1\n",
        "        \n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CHUNKS BASE\n",
        "chunks = main(text_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXPORT BASE\n",
        "import json\n",
        "with open(chunks_base, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(chunks, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "print(f\"Base data saved to {chunks_base}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "FINAL\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import spacy\n",
        "# nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SegmentChunks.process_json(chunks_base, json_file_path, Contents, WORD_LIMIT, nlp)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rag",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
