{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import faiss\n",
    "import logging\n",
    "from Libraries import C1_CreateSchema as C1, C2_Embedding as C2, C3_CheckStruct as C3\n",
    "from Config import Widgets, Configs, ModelLoader as ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets_list = Widgets.create_name_form()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Configs.WidgetValues(widgets_list)\n",
    "\n",
    "data_foler = config[\"data_folder\"]\n",
    "dcmt_path = config[\"dcmt_path\"]\n",
    "base_folder = config[\"base_folder\"]\n",
    "base_path = config[\"base_path\"]\n",
    "extracted_path = config[\"extracted_path\"]\n",
    "merged_path = config[\"merged_path\"]\n",
    "struct_path = config[\"struct_path\"]\n",
    "chunks_base = config[\"chunks_base\"]\n",
    "chunks_segment = config[\"chunks_segment\"]\n",
    "schema_ex_path = config[\"schema_ex_path\"]\n",
    "embedding_path = config[\"embedding_path\"]\n",
    "torch_path = config[\"torch_path\"]\n",
    "faiss_path = config[\"faiss_path\"]\n",
    "mapping_path = config[\"mapping_path\"]\n",
    "map_data_path = config[\"map_data_path\"]\n",
    "meta_path = config[\"meta_path\"]\n",
    "\n",
    "FILE_TYPE = config[\"FILE_TYPE\"]\n",
    "DATA_KEY = config[\"DATA_KEY\"]\n",
    "EMBE_KEY = config[\"EMBE_KEY\"]\n",
    "SWITCH = config[\"SWITCH\"]\n",
    "EMBEDD_MODEL = config[\"EMBEDD_MODEL\"]\n",
    "SEARCH_EGINE = config[\"SEARCH_EGINE\"]\n",
    "RERANK_MODEL = config[\"RERANK_MODEL\"]\n",
    "RESPON_MODEL = config[\"RESPON_MODEL\"]\n",
    "API_KEY = config[\"API_KEY\"]\n",
    "\n",
    "WORD_LIMIT = config[\"WORD_LIMIT\"]\n",
    "\n",
    "SEARCH_ENGINE = faiss.IndexFlatIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded model\n",
    "cached_path = \"../Models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML.CudaCheck()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if SWITCH == \"Auto Model\":\n",
    "    if os.path.exists(cached_path):\n",
    "        tokenizer, model = ML.load_auto_model(cached_path, device)\n",
    "        print(f\"ℹ️ Auto Model: {cached_path}\")\n",
    "        if model is None:\n",
    "            tokenizer, model = ML.load_auto_model(EMBEDD_MODEL, device)\n",
    "    else:\n",
    "        print(f\"ℹ️ Auto Model: {EMBEDD_MODEL}\")\n",
    "        tokenizer, model = ML.load_auto_model(EMBEDD_MODEL, device)\n",
    "\n",
    "elif SWITCH == \"Sentence Transformer\":\n",
    "    if os.path.exists(cached_path):\n",
    "        model = ML.load_sentence_model(cached_path, device)\n",
    "        print(f\"ℹ️ Sentece Transformer: {cached_path}\")\n",
    "\n",
    "        if model is None:\n",
    "            model = ML.load_sentence_model(EMBEDD_MODEL, device)\n",
    "    else:\n",
    "        print(f\"ℹ️ Sentece Transformer: {EMBEDD_MODEL}\")\n",
    "        model = ML.load_sentence_model(EMBEDD_MODEL, device)\n",
    "\n",
    "print(f\"✅ Using: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemaEx = C1.JSONSchemaExtractor(\n",
    "    list_policy=\"first\", \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Embedding = C2.JSONEmbedding(\n",
    "    model=model,\n",
    "    device=\"cuda:0\",\n",
    "    batch_size=32,\n",
    "    show_progress=False,\n",
    "    flatten_mode=\"split\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FaissConverter = D0.Torch2FaissConverter(\n",
    "    schema_ex_path=schema_ex_path,\n",
    "    torch_path=torch_path,\n",
    "    faiss_path=faiss_path,\n",
    "    mapping_path=mapping_path,\n",
    "    map_data_path=map_data_path,\n",
    "    keep_last=2,\n",
    "    nlist=100,\n",
    "    mode=EMBE_KEY,\n",
    "    use_pickle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schemaRun():\n",
    "    if os.path.exists(chunks_segment):\n",
    "        schemaEx.schemaRun(chunks_segment, schema_path=schema_ex_path)\n",
    "        chunksSchema = A0.read_json(schema_ex_path)\n",
    "        print(chunksSchema)\n",
    "    else:\n",
    "        print(f\"{chunks_segment} does not exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddingRun():\n",
    "    if os.path.exists(chunks_segment):\n",
    "        Embedding.embeddingRun(\n",
    "            json_path = chunks_segment,\n",
    "            schema_path = schema_ex_path,\n",
    "            torch_path = torch_path,\n",
    "            data_key = DATA_KEY,\n",
    "            embe_key = EMBE_KEY,\n",
    "            skip_if_exists = False,\n",
    "        )\n",
    "        \n",
    "        C3.print_json(DATA_KEY, EMBE_KEY, torch_path)\n",
    "    \n",
    "    else:\n",
    "        print(f\"{chunks_segment} does not exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemaRun()\n",
    "embeddingRun()\n",
    "FaissConverter.convert()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
